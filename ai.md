## Pytorch

### 1.å…³äºConv2dç±»å’Œconv2dæ–¹æ³•çš„ç†è§£ï¼š

â€‹	å‰è€…æ˜¯ç±»ï¼Œåè€…æ˜¯æ–¹æ³•ï¼Œç”¨æ³•çš„åŒºåˆ«æ˜¯ï¼š

â€‹	**Conv2dï¼š**

â€‹		å…ˆå®ä¾‹åŒ–ï¼šm = torch.nn.Conv2d(input_channel,output_channel,kernel,â€¦ï¼Œ)

â€‹		å†è°ƒç”¨å¯¹è±¡é‡Œçš„æ–¹æ³•ï¼š	output = m(input)

â€‹	**conv2d:**

â€‹	output = conv2d(input,â€¦å…¶å®ƒå‚æ•°)

â€‹	**äºŒè€…çš„å…³ç³»ï¼š**

â€‹		conv2dæ˜¯æ›´åº•å±‚çš„è½®å­ï¼Œæ›´å‡†ç¡®æ¥è¯´ï¼Œå®ƒæ‰€å±äºçš„ç±»torch.nn.functional( )æ˜¯ä¸€ä¸ªæ›´åº•å±‚çš„ç±»

â€‹		Conv2dç­‰å±äºtorch.nnçš„ç±»æ˜¯ç”±conv2dç­‰åŠŸèƒ½å°è£…å¥½çš„ç±»ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œç»å…¸çš„å·ç§¯ç¥ç»ç½‘ç»œã€å¾ªç¯ç¥ç»ç½‘ç»œã€transformerè¿™äº›å±‚PyTorchéƒ½ç»™å°è£…å¥½äº†ï¼Œåªéœ€è¦ç”¨æˆ·ä¼ å…¥å‡ ä¸ªå‚æ•°å®ä¾‹åŒ–å°±å¯ä»¥ã€‚

â€‹		ä½†æ˜¯å¯¹äºä¸€äº›éå…¸å‹ç½‘ç»œï¼Œå°±ä¸èƒ½ç›´æ¥è°ƒç”¨äº†ï¼Œéœ€è¦ç”¨conv2dæˆ–è€…Conv2dç»§ç»­å°è£…ï¼Œæ¯”å¦‚æœ¬ç§‘æ¯•è®¾çš„åŸºäºç‰©ç†è§„å¾‹çš„å¾ªç¯ç¥ç»ç½‘ç»œã€‚



### 2.å…³äºPytorchä¸­å·ç§¯æ“ä½œçš„ç†è§£

â€‹	å·ç§¯æ ¸çš„å°ºå¯¸å¹¶ä¸æ˜¯ç®€å•çš„Hk Ã— Wkï¼Œè€Œæ˜¯ä¸€ä¸ªå››ç»´å¼ é‡ï¼Œå½¢çŠ¶ä¸ºï¼ˆout_channelï¼Œin_channel/groupsé»˜è®¤ä¸º1ï¼ŒHkï¼ŒWkï¼‰ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæœ‰out_channel x in_channelè¿™ä¹ˆå¤šä¸ªäºŒç»´å·ç§¯æ ¸ï¼Œå¯¹è¾“å…¥çš„æ¯ä¸€ä¸ªin_channelå¯¹åº”ä¸€ä¸ªå·ç§¯æ ¸ï¼Œå…¨éƒ¨åŠ ä¸€èµ·ï¼ˆæˆ–è€…å¹³å‡ï¼Ÿï¼‰ä¹‹åæ‰ç”Ÿæˆä¸€ä¸ªè¾“å‡ºç‰¹å¾å›¾ï¼Œæƒ³è¦è¾“å‡ºå¤šout_channelä¸ªç‰¹å¾å›¾ï¼Œå°±å¾—å¯¹æ¯ä¸€ä¸ªout_channelå†é…**ä¸€ç»„**å·ç§¯æ ¸ã€‚

â€‹	conv2dæ–¹æ³•é‡Œä¼ å…¥çš„weightå‚æ•°å°±æ˜¯ä¸€ä¸ªå››ç»´å¼ é‡ï¼Œè¿™ä¸ªå››ç»´å¼ é‡ä½œç”¨äºä¼ å…¥çš„åŒæ ·æ˜¯å››ç»´çš„inputï¼Œäº§ç”Ÿout putã€‚æ‰€ä»¥ä¼ å…¥çš„è¿™ä¸€å¤§ç»„å·ç§¯æ ¸éƒ½è¦è‡ªå·±æå‰å†™å¥½/ç”Ÿæˆå¥½ï¼Œåæ­£å°±æ˜¯å¾—æå‰å‡†å¤‡å·ç§¯æ ¸ã€‚

â€‹	Conv2dç±»ä¸­ï¼Œä¸éœ€è¦è‡ªå·±æå‰å‡†å¤‡å¥½è¿™ä¸ªå››ç»´çš„å·ç§¯æ ¸ç»„ï¼Œåªéœ€è¦ä¼ å…¥input_channelå’Œout_channelï¼Œä»¥åŠkernel_sizeï¼Œï¼ˆè¿˜æœ‰groupsï¼‰è¿™ä¸ªç±»å°±ä¼šè‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªæœä»æ­£æ€åˆ†å¸ƒçš„å››ç»´å·ç§¯æ ¸ç»„ã€‚

â€‹	![image-20221016155853683](C:\Users\15054\AppData\Roaming\Typora\typora-user-images\image-20221016155853683.png)

å¹¶ä¸”è¿™ä¸ªå·ç§¯æ ¸ç»„æ˜¯å¯ä»¥é€šè¿‡å­¦ä¹ æ¥æ”¹å˜çš„ï¼Œé€šè¿‡Conv2d.weightå˜é‡å¯ç›´æ¥è®¿é—®ã€‚



![img](https://img-blog.csdnimg.cn/20191019210408246.png#pic_center)



â€‹	**å…¶å®ƒå‚æ•°è®²è§£ï¼š**

â€‹	**in_channels**ã€**out_channels**ã€**kernel_size**ã€**groups**(ç”¨äºåˆ†ç»„ï¼Œä¸€èˆ¬è®¾ç½®ä¸ºé»˜è®¤çš„1)ç”¨äºç”Ÿæˆéšæœºåˆå§‹åŒ–çš„å·ç§¯æ ¸ç»„

â€‹	**kernel_size**ã€**stride**ã€**padding**ã€**dilation**ç”¨äºè®¡ç®—ç”Ÿæˆçš„å›¾åƒçš„å°ºå¯¸

â€‹			ï¼ˆä¹Ÿå°±æ˜¯è¯´ï¼Œç”Ÿæˆå›¾åƒçš„å°ºå¯¸ä¸èƒ½ç›´æ¥æŒ‡å®šï¼Œåè€Œæ˜¯éœ€è¦æ ¹æ®ç”Ÿæˆçš„å°ºå¯¸æ¥åå‘è®¡ç®—strideï¼Œpaddingè¿™äº›ï¼Œdilationä¸€èˆ¬ä¸º1ï¼‰

â€‹	<img src="C:\Users\15054\AppData\Roaming\Typora\typora-user-images\image-20221016160205808.png" alt="image-20221016160205808" style="zoom:67%;" />

â€‹	è¿™å‡ ä¸ªå‚æ•°æ—¢å¯ä»¥æ˜¯ä¸€ä¸ªintå‹å˜é‡ï¼Œè¡¨ç¤ºåœ¨Hå’ŒWä¸¤ä¸ªç»´åº¦ä¸Šç›¸åŒï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªintçš„å…ƒç»„ï¼Œè¡¨ç¤ºåœ¨Hå’ŒWä¸Šçš„ä¸¤ä¸ªç»´åº¦

â€‹	æ³¨æ„ï¼šdilationé»˜è®¤ä¸º1ï¼Œè¡¨ç¤ºkernelä¸­çš„å…ƒç´ è§æ²¡æœ‰é—´éš”ï¼Œä¸º2æ‰è¡¨ç¤ºæœ‰ä¸€ä¸ªé—´éš”

â€‹	**bias**è¡¨ç¤ºæ˜¯å¦è¦åœ¨æ¯ä¸€ä¸ªchannelä¸Šç”Ÿæˆçš„ç‰¹å¾å›¾ä¸ŠåŠ ä¸€ä¸ªåå·®biasï¼Œé»˜è®¤ä¸ºfalseï¼Œå½¢çŠ¶ä¸ºé•¿åº¦æ˜¯out_channelsçš„ä¸€ç»´tensorï¼Œè¿™ä¸ªå‚æ•°ä¹Ÿæ˜¯å¯ä»¥å­¦ä¹ çš„ï¼Œå¯é€šè¿‡Conv2d.biaså±æ€§æŸ¥çœ‹ã€‚

â€‹	**padding_mode**è¡¨ç¤ºpaddingçš„æ–¹å¼ï¼ŒåŒ…å«'zeros'ï¼Œ'reflect'ï¼Œ'replicate'ï¼Œ'circular'å››ç§æ–¹å¼ï¼Œ

â€‹	é»˜è®¤zeroï¼Œç”¨0å¡«å……

â€‹	reflectè¡¨ç¤ºä»¥çŸ©é˜µè¾¹ç¼˜ä½å¯¹ç§°è½´ï¼Œå°†çŸ©é˜µä¸­çš„å…ƒç´ å¯¹ç§°çš„å¡«å……åˆ°æœ€å¤–å›´

â€‹	replicateè¡¨ç¤ºå°†çŸ©é˜µçš„è¾¹ç¼˜å¤åˆ¶å¹¶å¡«å……åˆ°çŸ©é˜µçš„å¤–å›´

â€‹	circularå°±æ˜¯å¾ªç¯,[æŒ‰å¡«å……åå°ºå¯¸   ä¸­å¿ƒæˆªå–  è¾“å…¥å›¾åƒå°ºå¯¸ä¸Šå¾ªç¯å¹³é“ºçš„ç»“æœ]([PyTorch Conv2dä¸­çš„å››ç§å¡«å……æ¨¡å¼è§£æ - ç®€ä¹¦ (jianshu.com)](https://www.jianshu.com/p/a6da4ad8e8e7))

â€‹	**device**è¡¨ç¤ºå°†å®ä¾‹åŒ–çš„å·ç§¯å±‚å¯¹è±¡æ”¾åœ¨å“ªä¸ªè®¾å¤‡ä¸Šä½¿ç”¨



### 3.æ± åŒ–

#### æ± åŒ–çš„ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ

â€‹	**ç‰¹å¾é™ç»´**ï¼Œé™ä½è®¡ç®—èµ„æºçš„æŸè€—

â€‹	æ± åŒ–çš„æ€æƒ³æ¥æºäºå›¾åƒç‰¹å¾èšåˆç»Ÿè®¡ï¼Œé€šä¿—ç†è§£å°±æ˜¯**æ± åŒ–è™½ç„¶ä¼šä½¿å¾—å›¾åƒå˜å¾—æ¨¡ç³Šä½†ä¸å½±å“å›¾åƒçš„è¾¨è®¤è·Ÿä½ç½®åˆ¤æ–­**

â€‹	ä¸€ä¸ªå½¢è±¡æ¯”å–»ï¼š1080påˆ°720p

#### MaxPool2dç±»å‚æ•°è¯¦è§£

â€‹	å…·ä½“é“¾æ¥è§[å®˜æ–¹æ–‡æ¡£]([MaxPool2d â€” PyTorch 1.12 documentation](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d))

â€‹	`torch.nn.MaxPool2d`

â€‹	(***kernel_size***, ***stride**=None*, ***padding**=0*, ***dilation**=1*, ***return_indices**=False*, ***ceil_mode**=False*)

â€‹	é¦–å…ˆæ˜ç¡®ï¼Œæ± åŒ–æ“ä½œä¸ä¼šæ”¹å˜ç‰¹å¾çš„channelæ•°ï¼Œæ‰€ä»¥ä¸ç”¨ä¼ å…¥in_channelå’Œout_channelä¸¤ä¸ªå‚æ•°ã€‚

â€‹	thenï¼Œæ± åŒ–å°±æ˜¯æŒ‰ç…§ä¸€å®šè§„åˆ™åœ¨kernel_sizeçª—å£å†…äº§å‡ºä¸€ä¸ªå€¼ï¼Œè§„åˆ™å›ºå®šï¼Œæ‰€ä»¥ä¸å­˜åœ¨å¯ä»¥å­¦ä¹ çš„å·ç§¯æ ¸å’Œbiasã€‚

â€‹	ä¸Conv2dç±»ç›¸åŒï¼Œä¸ä¼šç›´æ¥ä¼ å…¥input_tensorï¼Œè€Œæ˜¯å…ˆå®ä¾‹åŒ–ä¹‹åå†ä¼ å…¥inputã€‚

â€‹	inputå’Œoutputçš„å½¢çŠ¶ä¹‹åHå’ŒWä¸åŒï¼Œbatch_sizeå’Œchannelæ•°éƒ½ç›¸åŒï¼Œå¦‚ä¸‹å›¾ï¼š

â€‹	<img src="C:\Users\15054\AppData\Roaming\Typora\typora-user-images\image-20221016170451495.png" alt="image-20221016170451495" style="zoom:67%;" /> 

â€‹	**kernel_size**ã€**stride**ã€**padding**ã€**dilation**å››ä¸ªå‚æ•°åŒæ ·ç”¨äºè®¡ç®—è¾“å‡ºHå’ŒW

â€‹	strideæ¯”è¾ƒç‰¹æ®Šï¼Œå®ƒçš„é»˜è®¤å€¼ä¸å†æ˜¯1äº†ï¼Œè€Œæ˜¯kernel_size,æ„æ€å°±æ˜¯æœ€å¤§æ± åŒ–æ“ä½œä¸ä¼šè®©çª—å£åŒºåŸŸé‡å ã€‚

â€‹	**æ²¡æœ‰padding_mode**ï¼Œå› ä¸ºæœ€å¤§æ± åŒ–ï¼Œå–æœ€å¤§å€¼ï¼Œæ‰€ä»¥è¯¥ç±»ä¼šè‡ªåŠ¨åœ¨paddingåŒºåŸŸå¡«å……0ã€‚ï¼ˆmaxpool2dæ–¹æ³•ä¼šå¡«å……è´Ÿæ— ç©·ï¼‰

â€‹	**ceil_mode**ï¼šåœ¨çª—å£åŒºåŸŸç§»åŠ¨åˆ°inputå›¾åƒè¾¹ç¼˜æ—¶ï¼Œå¯èƒ½ä¼šå› ä¸ºçª—å£å¤ªå¤§å¯¼è‡´æ— æ³•å¡«æ»¡çª—å£ï¼Œå¦‚æœceil_modeä¸ºtrueï¼Œåˆ™ä¼šå¯¹æ²¡å¡«æ»¡çš„åœ°æ–¹å¡«ä¸Š0ï¼Œå†é€‰æœ€å¤§å€¼ï¼Œå¹¶è¾“å‡ºç»™output

â€‹		å¦‚æœceil_modeä¸ºfalseï¼Œä¹Ÿå°±æ˜¯flooræ¨¡å¼ï¼Œåˆ™ä¼šç›´æ¥èˆå¼ƒæ²¡å¡«æ»¡çš„åŒºåŸŸï¼Œä¹Ÿå°±æ˜¯è¯´è¿™ä¸€ä¸ªåŒºåŸŸä¸ä¼šäº§ç”Ÿoutputã€‚

â€‹	æ‰€ä»¥ï¼Œceil_modeä¼šå½±å“outputçš„Hå’ŒWã€‚

â€‹	å…¶å®ceilå’Œfloorå¾ˆå½¢è±¡ï¼Œåˆ†åˆ«ä»£è¡¨å¤©èŠ±æ¿å’Œåœ°æ¿ï¼Œå¯ä»¥ç†è§£ä¸ºï¼ŒHå’ŒWæ˜¯æ ¹æ®è®¡ç®—å‡ºæ¥Houtå’ŒHinå‘ä¸Šå–æ•´è¿˜æ˜¯å‘ä¸‹å–æ•´ã€‚

â€‹	**return_indices**ï¼šï¼ˆæš‚æ—¶ä¸æ˜¯å¾ˆæ‡‚ï¼‰è¿”å›outputçš„åŒæ—¶ï¼Œè¿”å›æ¯ä¸€ä¸ªçª—å£åŒºåŸŸå†…æœ€å¤§å€¼çš„ç´¢å¼•ï¼Œåç»­å¯¹[`torch.nn.functional.max_unpool2d`](https://pytorch.org/docs/stable/generated/torch.nn.functional.max_unpool2d.html#torch.nn.functional.max_unpool2d)è¿™ä¸ªæ–¹æ³•æœ‰ç”¨ã€‚



### 4.Normalizationå±‚

â€‹	ï¼ˆå½’ä¸€åŒ–/æ­£æ€åŒ–è€Œä¸æ˜¯æ­£åˆ™åŒ–ï¼ï¼æ­£åˆ™åŒ–åº”è¯¥æ˜¯ regularizationï¼‰ç¿»è¯‘ä¸Šæœ‰æ­£æ€åŒ–å’Œæ­£åˆ™åŒ–ï¼Œä½†å…¶å®æ­£åˆ™åŒ–æ˜¯ä¸å‡†ç¡®çš„ï¼Œå› ä¸ºæ­£åˆ™åŒ–é€šå¸¸è¡¨ç¤ºæœºå™¨å­¦ä¹ ä¸­çš„ä¸€ç§æƒé‡æƒ©ç½šæ–¹æ³•ï¼Œç”¨æ¥é˜²æ­¢è¿‡æ‹Ÿåˆã€æé«˜æ³›åŒ–èƒ½åŠ›ã€‚

â€‹	å¯¹å›¾åƒå¤„ç†åº”è¯¥ç”¨BatchNorm2d,è¾“å…¥è¾“å‡ºå½¢çŠ¶ç›¸åŒï¼ŒN x C x H x Wã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸ä¼šæ”¹å˜è¾“å…¥å½¢çŠ¶ã€‚

â€‹	<img src="C:\Users\15054\AppData\Roaming\Typora\typora-user-images\image-20221016190125528.png" alt="image-20221016190125528" style="zoom:80%;" />

â€‹	å°†æ‰€æœ‰çš„åƒç´ ç‚¹å€¼æŒ‰ç…§è¿™ä¸ªæ–¹æ³•è¿›è¡Œå½’ä¸€åŒ–

â€‹	Exå’ŒVaråˆ†åˆ«æ˜¯æ–¹å·®ï¼Œæ¯ä¸€ä¸ªchannelæ±‚ä¸€ä¸ªï¼Œæ‰€ä»¥æ•°é‡æœ‰Cä¸ªã€‚

â€‹	Î³æ˜¯æƒé‡ï¼ŒÎ²æ˜¯åç½®ï¼Œä½œç”¨æ˜¯å¯¹æ ‡å‡†æ­£æ€åˆ†å¸ƒè¿›è¡Œå˜åŒ–ï¼ˆå˜åŒ–æ–¹å·®å’Œå‡å€¼ï¼‰ã€‚å¯¹æ¯ä¸€ä¸ªchannelæ±‚ä¸€ä¸ªï¼Œæ‰€ä»¥å®ƒçš„å½¢çŠ¶åº”è¯¥ä¸ºC(è·ŸBatch_sizeæ— å…³ï¼ï¼ï¼)ï¼Œå¯ä»¥é€šè¿‡å±æ€§`.weight`å’Œ`.bias`æ¥æŸ¥çœ‹

â€‹	è¿™ä¸¤ä¸ªå‚æ•°ä¸éœ€è¦ä¼ å…¥ï¼ŒBatchNormç±»ä¼šè‡ªåŠ¨ç”Ÿæˆè¿™ä¸¤ä¸ªå˜é‡å¹¶èµ‹ç»™åˆå§‹å€¼1å’Œ0ï¼ˆç±»ä¼¼äºConv2dä¸­çš„å·ç§¯æ ¸ï¼Œä¸ç”¨ä¼ å…¥ï¼ŒåŒæ ·çš„ï¼Œè¿™ä¸¤ä¸ªå‚æ•°ä¹Ÿæ˜¯å¯ä»¥å­¦ä¹ çš„ï¼Œä½†è¿˜å¾—çœ‹affineå…³é”®å­—æ˜¯å¦ä¸ºTrueï¼‰

â€‹	**æ‰€æœ‰å‚æ•°**

>  torch.nn.BatchNorm2d (***num_features*,** ***eps**=1e-05*, ***momentum**=0.1*, ***affine**=True*, ***track_running_stats**=True*, ***device**=None*, ***dtype**=None*)

â€‹	**num_feature**:ç‰¹å¾å›¾çš„æ•°é‡ï¼Œå°±æ˜¯channelï¼Œè¡¨æ˜Î³å’ŒÎ²çš„ä¸ªæ•°ã€‚ï¼ˆRGBå›¾ç‰‡è‚¯å®šæ˜¯3ï¼‰

â€‹	 **momentum**=0.1ï¼Œç”¨äºå­¦ä¹ è¿‡ç¨‹ä¸­æ›´æ–°Î³å’ŒÎ²å‚æ•°

#### <img src="C:\Users\15054\AppData\Roaming\Typora\typora-user-images\image-20221016191301561.png" alt="image-20221016191301561" style="zoom:67%;" />

â€‹		è¡¨ç¤ºæ–°è§‚å¯Ÿåˆ°çš„xtiï¼ˆä¸æ˜¯å¾ˆç†è§£ï¼‰å¯¹å‚æ•°æ›´æ–°æ‰€å çš„æƒé‡ã€‚

â€‹	**affine**=True:æ§åˆ¶Î³å’ŒÎ²æ˜¯å¦å¯å­¦ä¹ ï¼Œé»˜è®¤ä¸ºTrueï¼Œå³å¯å­¦ä¹ ï¼Œfalseå³ä¸å¯å­¦ä¹ ã€‚

â€‹	**tracking_running_stats**ï¼šæš‚æ—¶ä¸ç”¨äº†è§£

â€‹	ï¼ˆå‰©ä¸‹ä¸¤ä¸ªå°±ä¸è§£é‡Šäº†ï¼‰

### 5.DropOut

#### ç›®çš„

â€‹	é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆï¼š

â€‹	å®ƒå¼ºè¿«ä¸€ä¸ªç¥ç»å•å…ƒï¼Œå’ŒéšæœºæŒ‘é€‰å‡ºæ¥çš„å…¶ä»–ç¥ç»å•å…ƒå…±åŒå·¥ä½œï¼Œè¾¾åˆ°å¥½çš„æ•ˆæœã€‚æ¶ˆé™¤å‡å¼±äº†ç¥ç»å…ƒèŠ‚ç‚¹é—´çš„è”åˆé€‚åº”æ€§ï¼Œå¢å¼ºäº†æ³›åŒ–èƒ½åŠ›ã€‚

â€‹	ã€å…¶å®ƒé˜²æ­¢è¿‡æ‹Ÿåˆçš„æ‰‹æ®µã€‘

â€‹		1.ç”¨éªŒè¯é›†ï¼ˆvalidationï¼‰ï¼Œå½“åœ¨éªŒè¯é›†ä¸Šæ•ˆæœå˜å·®æ—¶ï¼Œæå‰ç»ˆæ­¢è®­ç»ƒ

â€‹		2.æ­£åˆ™åŒ–ï¼šL1å’ŒL2åŠ æƒï¼Œé™åˆ¶å‚æ•°

â€‹		3.ensembleæ‰‹æ®µï¼Œè®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼Œè”åˆåˆ¤æ–­ã€‚ï¼ˆä½†æ˜¯è¿™ç§æ–¹æ³•è®­ç»ƒæˆæœ¬å¤ªé«˜äº†ï¼‰

â€‹		4.dropout

â€‹		5.soft weight sharingï¼ˆæš‚æ—¶ä¸äº†è§£ï¼‰

#### DropOutç±»

> torch.nn.DropOut2d(***p**=0.5*, ***inplace**=False*)

â€‹	<img src="C:\Users\15054\AppData\Roaming\Typora\typora-user-images\image-20221016213403595.png" alt="image-20221016213403595" style="zoom:50%;" />

â€‹	ç»™æ¯ä¸€ä¸ª2ç»´ç‰¹å¾å›¾/ä¸€ç»´tensorLï¼ˆâ€å†å²åŸå› â€œï¼‰ä¸€ä¸ªæ¦‚ç‡pï¼Œä½¿å…¶ç½®é›¶

â€‹	ä¹Ÿå°±æ˜¯è¯´DropOut2dåŒ…å«äº†DropOut1dçš„åŠŸèƒ½ï¼Œå½“è¾“å…¥ä¸€ä¸ªä¸‰ç»´tensoråï¼Œä¼šæŒ‰ç…§1dçš„è§„åˆ™è¯†åˆ«æ¯ä¸€ä¸ªç»´åº¦ï¼Œè€Œä¸æ˜¯C,H,Wã€‚æ‰€ä»¥ç›®å‰çš„2dè¿˜ä¸æ”¯æŒä¸å¸¦batchçš„C,H,Wä¸‰ç»´æ•°æ®çš„2dç½®é›¶æ“ä½œã€‚

â€‹	éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒDropOutçš„è¾“å…¥ä¸æ˜¯ç¥ç»ç½‘ç»œä¸­æµåŠ¨çš„tensorï¼Œè€Œæ˜¯å…¶å®ƒå±‚ä¸­çš„å‚æ•°ï¼Œæ¯”å¦‚Conv2då±‚ã€å…¨è¿æ¥å±‚ä¸­çš„å‚æ•°ã€‚æ‰€ä»¥DropOutä¸€èˆ¬åœ¨å®šä¹‰å…¶å®ƒå±‚çš„æ—¶å€™ä¼šç”¨ã€‚

â€‹	ï¼ˆä½†æˆ‘æ„Ÿè§‰å…¶å®DropOut2då¹¶ä¸å¸¸ç”¨ï¼Œåè€Œæ˜¯é’ˆå¯¹æ¯ä¸€ä¸ªå…ƒç´ çš„DropOutæœ€å¸¸ç”¨ã€‚é‡åˆ°å†è¯´å§ï¼‰



### 6.æŸå¤±å‡½æ•°å±‚

#### L1Loss

torch.nn.L1Loss(**size_average** = None , **reduce** = None , **reduction** = 'mean')  

> æ³¨æ„ï¼šåœ¨ä½¿ç”¨importå¼•å…¥æŸä¸€ä¸ªç±»æ—¶ï¼Œä¸èƒ½ç›´æ¥import torch.nn.ç±»åï¼Œå› ä¸ºç›´æ¥ä½¿ç”¨importæ˜¯å¼•ç”¨åŒ…çš„ï¼Œåº”è¯¥ç”¨from torch.nn import ç±»åï¼Œæ¯”å¦‚ï¼šfrom torch.nn import L1Loss

size_averageå’Œreduceä¸¤ä¸ªå‚æ•°å·²ç»æ²¡ç”¨äº†ï¼Œåªç”¨ä¸€ä¸ªreductionå‚æ•°ä¾¿å¯ä»¥å®ç°ä»–ä»¬ä¸¤ä¸ªçš„åŠŸèƒ½

â€‹	â­é¦–å…ˆè¯´æ˜ï¼Œpredictå’Œtargetå¯ä»¥æ˜¯ä»»æ„å½¢çŠ¶ï¼Œä¿è¯å®ƒä»¬ä¸¤ä¸ªå½¢çŠ¶ç›¸åŒå³å¯ã€‚åœ¨å®ä¾‹åŒ–L1Losså¯¹è±¡ä¹‹åï¼Œå†ä¼ å…¥è¿™ä¸¤ä¸ªå‚æ•°ï¼Œè¾“å‡ºä¸€ä¸ªoutput

```python
#å®ä¾‹åŒ–è¿™ä¸ªç±»
loss = L1Loss()
#ä¼ å…¥å‚æ•°
output = loss(predict,target)
```



**reduction**ï¼šå¯ä»¥æŒ‡å®šä¸‰ä¸ªå€¼ï¼Œâ€˜noneâ€™,'mean','sum'

â€‹	none:åªå¯¹æ‰€æœ‰å…ƒç´ è¿›è¡Œ|x-y|æ“ä½œï¼Œè¾“å‡ºoutputä¸æ˜¯æ ‡é‡ï¼Œè€Œæ˜¯ä¸€ä¸ªä¸predictå’Œtargetç›¸åŒå½¢çŠ¶çš„tensor

â€‹	meanï¼šæ±‚æ‰€æœ‰å…ƒç´ |x-y|çš„sumï¼Œç„¶åé™¤ä»¥nï¼Œè¾“å‡ºä¸€ä¸ªæ ‡é‡

â€‹	sumï¼šæ±‚æ‰€æœ‰å…ƒç´ |x-y|çš„sumï¼Œä¸ç”¨é™¤ä»¥nï¼Œè¾“å‡ºä¸€ä¸ªæ ‡é‡

â€‹	

#### MSELoss

â€‹	å‚æ•°å’Œè§„åˆ™ä¸L1Losså®Œå…¨ç›¸åŒï¼Œåªä¸è¿‡æŠŠ|x-y|æ¢æˆäº†ï¼ˆx-yï¼‰^2



#### CrossEntropyLoss_äº¤å‰ç†µ

â€‹	torch.nn.CrossEntropyLoss()

â€‹	é¦–å…ˆè¯´æ˜è¾“å…¥è¾“å‡ºï¼š

â€‹	![image-20221017172310032](C:\Users\15054\AppData\Roaming\Typora\typora-user-images\image-20221017172310032.png)

Inputï¼Œä¹Ÿå°±æ˜¯predictçš„è¾“å…¥è‚¯å®šæ˜¯N,Cæˆ–C

targetå¯èƒ½æ˜¯one_hotç¼–ç ï¼Œåˆ™ä¸è¾“å…¥å½¢çŠ¶ç›¸åŒ

â€‹			ä¹Ÿå¯èƒ½åªæ˜¯ä¸€ä¸ªæ­£ç¡®çš„ç´¢å¼•ï¼Œåˆ™ä¼šå°‘æ‰Cè¿™ä¸€ç»´ï¼Œå³ä¸€ç»´é•¿åº¦ä¸ºNçš„tensoræˆ–æ ‡é‡

è¾“å‡ºï¼Œå¦‚æœreduction = â€˜sum' æˆ–è€…â€˜meanâ€™ï¼Œå°±æ˜¯ä¸€ä¸ªæ ‡é‡

â€‹			å¦‚æœreduction = â€˜noneâ€™ï¼Œåˆ™ä¸Targetå½¢çŠ¶ç›¸åŒï¼ˆä¸€èˆ¬ä¸ç”¨ï¼‰

â€‹	â­å‚æ•°ï¼š

â€‹			åªç†è§£ä¸€ä¸ªreductionå°±å¥½ï¼Œå…¶å®ƒä¸ç”¨ç®¡f



### 7.PyTorchç»“æ„åˆ’åˆ†

torch

**åˆå§‹åŒ–tensorçš„ä¸€äº›æ–¹æ³•ï¼š**

torch.normal()æ­£æ€åˆ†å¸ƒ   /   torch.randn()æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼ˆmean=0,std=1ï¼‰

torch.ones()  /  torch.zeros()

torch ones_like()  /  torch.zeros_like()

**æœ‰å…³ç½‘ç»œæ„å»º**

torch.nn  

â€‹	torch.nn.functional

â€‹	torch.nn.Parameter

â€‹	torch.nn.Conv2dç­‰

â€‹	torch.nn.init.normal_/randn_()  ä½¿ç”¨normalæˆ–è€…randnä¿®æ”¹tensorçš„å€¼

â€‹	nné‡Œè¿˜æœ‰æŸå¤±å‡½æ•° torch.nn.MSELoss()

**ä¼˜åŒ–å™¨**:

torch.optim

**æ¿€æ´»å‡½æ•°**

torch.relu/torch.sigmoidç­‰ 

**å…¶å®ƒåŠŸèƒ½å‡½æ•°ï¼š**

torch.max(a,b)

torch.min(a,b)

â€‹		è¾“å‡ºä¸€ä¸ªtensorï¼Œå½¢çŠ¶ä¸aï¼Œbç›¸åŒï¼Œå…¶å…ƒç´ å€¼ä¸ºaï¼Œbä¸­çš„max/minå€¼

torch.norm(input, p=2)

â€‹		æ±‚inputçš„LpèŒƒæ•°



### 8.è‡ªå®šä¹‰loss/updaterå’Œpytorchè‡ªå¸¦loss/updaterä½¿ç”¨ä¸Šçš„åŒºåˆ«



>  d2lä¸Šæœ‰è‡ªå®šä¹‰çš„losså’Œupdaterï¼Œåœ¨åä¼ æ—¶äºpytorchè‡ªå¸¦çš„losså’Œupdateråœ¨ç”¨æ³•ä¸Šæœ‰ä¸€äº›åŒºåˆ«



**è‡ªå®šä¹‰çš„**ï¼š

```python
# è‡ªå®šä¹‰çš„loss
def squared_loss(y_hat, y):  #@save
    """å‡æ–¹æŸå¤±"""
    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2
# è‡ªå®šä¹‰çš„sgd
def sgd(params, lr, batch_size):  #@save
    """å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™"""
    with torch.no_grad():
        for param in params:
            param -= lr * param.grad / batch_size
            param.grad.zero_()
```

 æ±‚lossçš„æ—¶å€™ä¿æŒäº†ç»´åº¦ï¼Œç›¸å½“äºreduction = â€™noneâ€˜

â€‹		ä½†æ˜¯åå‘ä¼ æ’­çš„æ—¶å€™åˆä¸èƒ½ç”¨å‘é‡æ±‚å¯¼ï¼Œæ‰€ä»¥éœ€è¦loss.sum().backward() 

sgdåœ¨æ›´æ–°æ¢¯åº¦æ—¶å€™é™¤ä»¥/batch_sizeï¼Œæ˜¯å› ä¸ºloss.sum()ï¼Œå¦‚æœæ˜¯loss.mean().backward()ï¼Œå°±ä¸ç”¨/batch_sizeäº†ï¼ˆè‡ªå¸¦çš„å°±æ˜¯è¿™æ ·åšçš„



**pytorchè‡ªå¸¦çš„ï¼š**

![image-20230317200547577](C:\Users\15054\AppData\Roaming\Typora\typora-user-images\image-20230317200547577.png)

lossé»˜è®¤æŸå¤±æ˜¯meanï¼Œæ‰€ä»¥åå‘ä¼ æ’­çš„æ—¶å€™ç›´æ¥ loss.backward()å°±å¯ä»¥

updateré‡Œçš„æºä»£ç è‚¯å®šä¹Ÿæ²¡æœ‰é™¤ä»¥batch_size



â­d2lä¸­train_ch3å‡½æ•°ä¼ å…¥lossçš„ç†è§£ï¼š

â€‹		å¯ä»¥çœ‹åˆ°è¯¥æ–¹æ³•åŒæ—¶ä¼ å…¥losså’Œupdaterï¼ŒæŒ‰ç…§æˆ‘ä»¬å‰é¢çš„æ€ç»´æƒ¯æ€§ï¼Œè¿™é‡Œä¼ å…¥çš„è¦ä¹ˆéƒ½æ˜¯è‡ªå®šä¹‰çš„ï¼Œè¦ä¹ˆéƒ½æ˜¯pytorchè‡ªå¸¦çš„ã€‚

â€‹		ä½†åœ¨è¿™é‡Œï¼Œä¼ å…¥çš„traineræ˜¯pytorchè‡ªå¸¦çš„ï¼Œlosså´ä¸æ˜¯æŒ‰é»˜è®¤reduction=â€™meanâ€˜,ä¸ºä»€ä¹ˆï¼Ÿ

â€‹		![image-20230317201318025](C:\Users\15054\AppData\Roaming\Typora\typora-user-images\image-20230317201318025.png)

â€‹		çœ‹ä¸‹train_ch3çš„æºä»£ç å°±çŸ¥é“äº†ï¼š

![image-20230317201253856](C:\Users\15054\AppData\Roaming\Typora\typora-user-images\image-20230317201253856.png)

â€‹		å…¶å®reduction = â€™noneâ€˜å°±ç­‰ä»·äºd2lä¸­è‡ªå®šä¹‰çš„square_lossï¼ŒäºŒè€…ä¼ å…¥å“ªä¸€ä¸ªéƒ½å¯ä»¥ï¼Œä½†æ˜¯ä¸èƒ½ä¼ å…¥é»˜è®¤çš„meanï¼ˆä¼ å…¥å°±ä¸èƒ½éšæ„åˆ‡æ¢meanå’Œsumäº†

â€‹		å¯¹å®ƒsum()å°±å¯ä»¥è·Ÿè‡ªå®šä¹‰çš„updateræ­é…ï¼Œå¯¹å®ƒæ±‚meanå°±å¯ä»¥è·Ÿpytorchçš„updateræ­é…

## å„ç§ç½‘ç»œ

### 	Resnet

<img src="C:\Users\15054\AppData\Roaming\Typora\typora-user-images\image-20230315192424313.png" alt="image-20230315192424313" style="zoom:50%;" />





# hugging face

## 1.raw_datasetçš„tokenize

>  raw_datasetå¯ä»¥ç”¨datasetsæ¨¡å—åŠ è½½

```python
from datasets import load_dataset

# å‰é¢è¡¨ç¤ºè¿™ä¸ªdatasetçš„åå­—ï¼Œåæ¥å°±æ˜¯configï¼ˆdataset_serverä¸­çš„ï¼‰ï¼Œä¹Ÿæœ‰çš„datasetæ²¡æœ‰config,é‚£å°±ä¸ç”¨å†™æˆ–è€…ç­‰äºdefault
raw_datasets =  load_dataset("glue", "mrpc")

# æŸ¥çœ‹åŠ è½½çš„è¿™ä¸ªæ•°æ®é›†çš„ç»“æ„
print(raw_dataset)
```

<img src=".\picture\å±å¹•æˆªå›¾ 2023-09-14 220509.png" alt="å±å¹•æˆªå›¾ 2023-09-14 220509" style="zoom:67%;" />

æ³¨æ„ï¼šè¿™ç§æ–¹å¼åŠ è½½æ‰€æœ‰çš„æ•°æ®é›†ï¼Œå¦‚æœåªæ˜¯**æŸ¥çœ‹æŸä¸ªå¤§æ•°æ®é›†ä¸­çš„æŸå‡ æ¡æ•°æ®/æŸ¥çœ‹æ•°æ®é›†çŠ¶æ€/åœ¨æŸæ•°æ®é›†ä¸­è¿›è¡ŒæŸ¥è¯¢**ä¹‹ç±»çš„æ“ä½œï¼Œå¹¶ä¸éœ€è¦åŠ è½½æ•´ä¸ªæ•°æ®é›†ï¼Œè¿™æ—¶å€™æ‰éœ€è¦dataset_server



> tokenizeçš„æµç¨‹

â€‹	ğŸš©é¦–å…ˆåº”è¯¥æ„è¯†åˆ°ï¼Œæ¨¡å‹å’Œä»»åŠ¡ç±»å‹åº”è¯¥æ˜¯åŒ¹é…èµ·æ¥çš„ï¼š

â€‹		å› ä¸ºcheckpointèƒ½åŒæ—¶å†³å®šæ¨¡å‹å’Œtokenizer,ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¨¡å‹ç¡®å®šäº†ï¼Œå®ƒå¯¹åº”çš„tokenizerå°±ç¡®å®šäº†ï¼Œ		   		tokenzierå¤„ç†raw_datasetçš„æ–¹å¼æ˜¯ä¸ä¸€æ ·çš„ï¼Œå¯¹åº”ç€æŸä¸€ç§å›ºå®šçš„ä»»åŠ¡ã€‚å³ï¼Œ**åœ¨hugging faceä¸­**ï¼Œæ¯ä¸€ç§		æ¨¡å‹éƒ½å¯¹åº”ç€ä¸€ç§ä¸‹æ¸¸ä»»åŠ¡

â€‹		åˆæ¯”å¦‚ï¼Œåˆ¤æ–­ä¸¤ä¸ªå¥å­å…³ç³»çš„æ¨¡å‹ï¼Œä¼šä¼ å…¥token_type_idsï¼Œè€Œå…¶ä»–ä»»åŠ¡ä¸ä¼šä¼ å…¥è¿™ä¸ªï¼Œæ‰€ä»¥å¹¶ä¸æ˜¯éšä¾¿ä¸€		ä¸ªæ¨¡å‹éƒ½èƒ½é€‚åº”äºå…¶ä»–nlpä»»åŠ¡çš„

â€‹	ä¹Ÿå°±æ˜¯è¯´ï¼Œllama2å¤§æ¨¡å‹ç”¨äºQAå’Œchat_completitionï¼Œå¯èƒ½å¹¶ä¸é€‚ç”¨äºæƒ…æ„Ÿåˆ¤æ–­è¿™äº›ä¸‹æ¸¸ä»»åŠ¡



â€‹	ğŸš©å¼€å§‹è®²è§£ï¼š

â€‹	æ‹¿åˆ°äº†æ•°æ®é›†ï¼Œæˆ‘ä»¬å°±çŸ¥é“è¦åšçš„ä»»åŠ¡æ˜¯å“ªä¸€ç§äº†ï¼Œå¯ä»¥åˆ°hugging faceå®˜æ–¹ç½‘ç«™ä¸Šæ ¹æ®ä»»åŠ¡ç±»å‹æŸ¥è¯¢ç›¸å…³çš„æ¨¡å‹ï¼Œå¹¶å°†æ¨¡å‹åå­—å­—ç¬¦ä¸²ç»™åˆ°checkpointã€‚

â€‹	ç„¶åæ ¹æ®checkpointå¾—åˆ°tokenizer(å’Œmodel

â€‹	ç”¨äºä¸åŒä»»åŠ¡çš„tokenizerä¼ å…¥çš„å‚æ•°ï¼ˆæ¯”å¦‚å‡ ä¸ªå¥å­ï¼‰æ˜¯ä¸ä¸€æ ·çš„ï¼Œè¿™æ ·åº”è¯¥ææ¸…æ¥š

â€‹	æ ¹æ®raw_datasetç»“æ„å’Œtokenizerç”¨æ³•ï¼Œå†™ä¸€ä¸ªtokenize_function

```python
# æ ¹æ®checkpointåŠ è½½tokenizer
from transformers import AutoTokenizer
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

# åœ¨è¿™ä¸€æ­¥ï¼Œæ— è®ºraw_datasetçš„ç»“æ„æ˜¯ä»€ä¹ˆæ ·çš„ï¼Œéƒ½å¯ä»¥è¿›è¡Œ
# mapçš„ä½œç”¨å°±æ˜¯å°†raw_datasetçš„æ¯ä¸€æ¡éƒ½æ‰”ç»™tokenize_functionå¤„ç†
tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)

# æ ¹æ®raw_datasetç»“æ„å’Œtokenizerç”¨æ³•ï¼Œå†™ä¸€ä¸ªtokenize_function
def tokenize_function(example):
    # paddingè¿™é‡Œåº”è¯¥æ˜¯æŒ‰ç…§é»˜è®¤çš„longest,ä¸ç„¶åé¢çš„input_idsä¸ä¼šä¸ä¸€æ ·
    return tokenize(example["sentence1"], example["sentence2"], truncation=True)

# è¿™é‡Œçš„batched=Trueå¹¶ä¸æ˜¯ç›´æ¥è¿”å›åˆ†å¥½çš„batch_sizeä¸º1000çš„æ•°æ®é›†ï¼Œè€Œæ˜¯å°†æœªå¤„ç†çš„æ•°æ®åˆ†ä¸ºbatché€ç»™tokenize_function,è€Œä¸æ˜¯ä¸€æ¡æ¡çš„å¤„ç†ï¼Œå¤„ç†å¥½åå†æŠŠæ‰€æœ‰çš„batchåˆå¹¶èµ·æ¥ï¼Œè¿™æ ·åšåªæ˜¯ä¸ºäº†æé«˜å¤„ç†é€Ÿåº¦ï¼ï¼

```

â€‹	å¾—åˆ°çš„tokenized_datasetså¦‚å›¾ï¼Œæˆ‘ä»¬éœ€è¦çš„åªæ˜¯è“è‰²éƒ¨åˆ†ï¼Œçº¢è‰²éƒ¨åˆ†çš„sentence1/2å’Œidxå…¶å®å·²ç»ä¸éœ€è¦äº†ã€‚

![](.\picture\image-20230914230720236.png)



> ä»tokenized_datasetsä¸­æå–éœ€è¦çš„æ•°æ®

â€‹	ä¸Šé¢å¯ä»¥çœ‹å‡ºï¼Œtokenized_datasetså¹¶ä¸æ˜¯æˆ‘ä»¬æœ€ç»ˆéœ€è¦çš„ç›´æ¥ä¼ å…¥æ¨¡å‹çš„æ•°æ®ï¼Œä¸€æ–¹é¢å®ƒåŒ…å«äº†train/val/testçš„æ‰€æœ‰æ•°æ®ï¼Œå¦ä¸€æ–¹é¢å®ƒåŒ…å«sentence1/2å’Œidxè¿™äº›ç”¨ä¸åˆ°çš„ä¿¡æ¯

```python
# æŠ½å–å‡ºtrainå’Œtestçš„æ•°æ®
train_samples = tokenized_datasets["train"]
test_samples = tokenized_datasets["test"]

# å‰”é™¤ä¸éœ€è¦çš„åˆ—
train_samples = {k: v for k, v in train_samples.items() if k not in ["idx", "sentence1", "sentence2"]}
test_samples = {k: v for k, v in test_samples.items() if k not in ["idx", "sentence1", "sentence2"]}

# æŸ¥çœ‹å‰å…«ä¸ªè®­ç»ƒæ ·æœ¬çš„input_idxçš„é•¿åº¦
[len(x) for x in train_samples["input_ids"][:8]]
è¾“å‡ºï¼š [50, 59, 47, 67, 59, 50, 62, 32]
```



> "DataLoader"

â€‹	è¿™ä¸€æ­¥æ˜¯ä¸ºäº†å‘æŒ¥DataLoaderçš„ä½œç”¨ï¼Œä½†æ˜¯batch_sizeä¸éœ€è¦åœ¨è¿™é‡Œä¼ å…¥ï¼Œè€Œæ˜¯åœ¨TrainingArgumentsç±»çš„å¯¹è±¡é‡Œä¼ å…¥Trainer()   

â€‹	batch_sizeå’Œdata collatorä¼ å…¥Traineråï¼ŒTrainerå¯¹è±¡å°†æ•°æ®åˆ’åˆ†ä¸ºä¸€ä¸ªä¸ªçš„"æœªå°è£…"batch,ç„¶åå°†å®ƒä»¬ä¸€ä¸ªä¸ªäº¤ç»™data collatorå¤„ç†ï¼Œæ‰€ä»¥data collatorçš„ä½œç”¨å°±æ˜¯**ä¸ç®¡ç»™ä»–å¤šå°‘çš„æ•°æ®ï¼Œéƒ½æŠŠå®ƒå°è£…ä¸ºé•¿åº¦ç›¸åŒçš„ä¸€ä¸ªbatch!!!**   ![](.\picture\image-20230915061724174.png)

â€‹	æ³¨æ„çœ‹ï¼Œä¸Šé¢å†™çš„æ˜¯**a** batch!!

â€‹	ä¸ºä»€ä¹ˆè¿˜è¦WithPaddingå‘¢ï¼Ÿ

â€‹		ä¸Šé¢çš„å‰å…«ä¸ªå¯ä»¥çœ‹åˆ°é•¿åº¦ä¸åŒï¼Œå¦‚æœæ¯ä¸€ä¸ªinput[ids]åªæ˜¯è¢«å•ç‹¬ç”¨äºä¸€å¥è¯çš„æ¨ç†ï¼Œé‚£ä¹ˆå®ƒè‡ªèº«å°±æ˜¯æ‰€æœ‰		æ•°æ®ï¼Œä¿æŒè‡ªå·±çš„é•¿åº¦å°±å¯ä»¥äº†ï¼Œä½†æ˜¯ç°åœ¨è¦è¿›è¡Œçš„æ˜¯è®­ç»ƒï¼Œä¸æ­¢æ˜¯è‡ªå·±äº†ï¼Œæ‰€æœ‰çš„éƒ½è¦ä¿æŒç›¸åŒçš„é•¿åº¦ã€‚

â€‹	è¿™é‡ŒDataCollatorWithPaddingä¸ä¼šæ˜¾ç¤ºçš„ä¼ å…¥

```python
from transformers import DataCollatorWithPadding

# ç”¨äºç”Ÿæˆdata_collatorå¯¹è±¡
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

# è¯•ä¸€ä¸‹data_collatorçš„æ•ˆæœï¼ˆå®é™…åœ¨hugging faceæ¡†æ¶å†…æˆ‘ä»¬ä¸ä¼šæ‰‹åŠ¨ç”¨collatorï¼Œè€Œæ˜¯å°†å…¶ä¼ å…¥Trainerå¯¹è±¡
batch = data.collator(train_samples[:8])
{k:v.shape for k, v in batch.items()}

è¾“å‡ºï¼š
{'attention_mask':torch.Size([8, 67]),
 'input_ids':torch.Size([8, 67]),
 'labels':torch.Size([8]),
 'token_type_ids':torch.Size([8, 67])
}
# è¿™é‡Œå°†ä¼ å…¥çš„å…«ä¸ªå›¾åƒå…¨éƒ¨å­˜å…¥ä¸€ä¸ªbatchä¸­äº†
```

## 2.ä½¿ç”¨Trainerè¿›è¡Œè®­ç»ƒ

> äº”ä¸ªåŸºæœ¬å‚æ•°

- model:å¿…é¡»æ˜¯åŒ…å«åå¤„ç†æ¨¡å—çš„ï¼Œæ¯”å¦‚model = AutoModelForSequenceClassification.from_pretrained(checkpoint,  num_labels=2)

- args:

  ```python
  from transformers import TrainingArguments
  training_args = TrainingArguments(output_dir="test_trainer", evaluation_strategy="no") 
  # æŒ‡å®šå­˜æ”¾æ¨¡å‹checkpointçš„æ–‡ä»¶å¤¹ï¼Œè¿™ä¸ªä¹Ÿç®—æ˜¯è¶…å‚æ•°ï¼Œå…¶ä»–è¶…å‚æ•°éƒ½æœ‰é»˜è®¤å€¼ï¼Œå¯ä»¥é»˜è®¤ä¹Ÿå¯ä»¥æŒ‡å®š
  # evaluation_strategyè¡¨ç¤ºå¤šä¹…æŸ¥çœ‹ä¸€æ¬¡è®­ç»ƒç»“æœï¼Œnoæ˜¯ä»ä¸æŸ¥çœ‹ï¼Œè¿˜æœ‰stepså’Œepochä¸¤ä¸ªå‚æ•°
  # è¶…å‚æ•°çš„é»˜è®¤å€¼è¯¦è§ï¼šhttps://huggingface.co/docs/transformers/v4.33.0/en/main_classes/trainer#transformers.TrainingArguments
  ```

- train_datasetï¼šç”±tokenizeå¤„ç†å®Œçš„æ•°æ®ï¼ˆä¸€èˆ¬é€šè¿‡map,æ•ˆç‡æ¯”è¾ƒé«˜ï¼Œä½†ä¸ä¸€å®šéå¾—ç”¨mapï¼‰

- test_datasetï¼šåŒä¸Š

- data_collatorï¼šå¥½åƒä¹Ÿæ˜¯éå¿…è¦

- compute_metrics = compute_metrics

  ```python
  import numpy as np
  import evaluate
  from datasets import load_metric
  
  # å¯ä»¥è‡ªå®šä¹‰
  metric = evaluate.load("accuracy")
  # ä¹Ÿå¯ä»¥åŠ è½½æ•°æ®é›†è‡ªå¸¦çš„è¯„ä»·æ ‡å‡†
  metirc = load_metric("glue", "mrpc")
  
  # ç„¶åè£…å…¥ä¸‹é¢è¿™ä¸ªå‡½æ•°ï¼Œå†™æ³•æ¯”è¾ƒå›ºå®šï¼Œä¸å¿…æ·±ç©¶ä¸ºä»€ä¹ˆï¼Œå°±æ˜¯å…ˆè§£åŒ…ç„¶åç”¨metric
  def compute_metrics(eval_pred):
      logits, labels = eval_pred
      predictions = np.argmax(logits, axis=-1)
      return metric.compute(predictions=predictions, references=labels)
  ```

  ![image-20230915065035687](.\picture\image-20230915065035687.png)

- tokenizerï¼šéå¿…è¦



> éå¸¸ç®€å•çš„è®­ç»ƒè¿‡ç¨‹



```python
from transformers import Trainer

# å…ˆå®ä¾‹åŒ–
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
)

# ç„¶åè®­ç»ƒ
trainer.train()
```

